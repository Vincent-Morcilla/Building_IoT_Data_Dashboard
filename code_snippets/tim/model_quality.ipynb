{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import brickschema\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "from rdflib import Namespace\n",
    "from rdflib.namespace import RDFS, SKOS, BRICK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENAPS = Namespace(\"http://senaps.io/schema/1.0/senaps#\")\n",
    "SENAPS['stream_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKOS['definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '../../datasets/bts_site_b_train/'\n",
    "\n",
    "dataset_zip = 'train.zip'\n",
    "dataset_path = Path(dataset_dir) / dataset_zip\n",
    "\n",
    "mapping_csv = 'mapper_TrainOnly.csv'\n",
    "mapping_path = Path(dataset_dir) / mapping_csv\n",
    "\n",
    "# building_ttl = 'Site_B_tim.ttl'\n",
    "building_ttl = 'Site_B.ttl'\n",
    "building_model = Path(dataset_dir) / building_ttl\n",
    "\n",
    "brick_ttl = 'Brick_v1.2.1.ttl'\n",
    "brick_schema = Path(dataset_dir) / brick_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_building = brickschema.Graph().load_file(building_model)\n",
    "g_brick = brickschema.Graph().load_file(brick_schema)\n",
    "# g_brick_latest = brickschema.Graph(load_brick=True)\n",
    "g_brick_latest = brickschema.Graph(load_brick_nightly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparql_to_df(g, q, **kwargs):\n",
    "    res = g.query(q, **kwargs)\n",
    "    df = pd.DataFrame(res.bindings)\n",
    "    # are these necessary?\n",
    "    df.columns = df.columns.map(str)\n",
    "    # df = df.map(str)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all brick entities and their classes in the building model\n",
    "def get_brick_entities(g):\n",
    "    q = '''\n",
    "    SELECT ?entity ?brick_class ?stream_id ?named_unit ?anonymous_unit WHERE {\n",
    "        ?entity a ?brick_class .\n",
    "        OPTIONAL { ?entity senaps:stream_id ?stream_id } .\n",
    "        OPTIONAL { ?entity brick:hasUnit ?named_unit .\n",
    "                    filter ( strstarts(str(?named_unit),str(unit:)) ) } .\n",
    "        OPTIONAL { ?entity brick:hasUnit [ brick:value ?anonymous_unit ] } .\n",
    "        filter ( strstarts(str(?brick_class),str(brick:)) ) .\n",
    "    }\n",
    "    '''\n",
    "    # q = '''\n",
    "    # SELECT ?entity ?brick_class ?stream_id WHERE {\n",
    "    #     ?entity a ?brick_class .\n",
    "    #     OPTIONAL { ?entity senaps:stream_id ?stream_id } .\n",
    "    #     filter ( strstarts(str(?brick_class),str(brick:)) ) .\n",
    "    # }\n",
    "    # '''\n",
    "    return sparql_to_df(g, q)\n",
    "\n",
    "get_brick_entities(g_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_brick_entities(g_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_in_brick(cls, g):\n",
    "    return (cls, None, None) in g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_in_provided_brick'] = df['brick_class'].apply(class_in_brick, args=(g_brick,))\n",
    "print(len(df[df['class_in_provided_brick'] == True]), 'recognised by provided Brick schema:')\n",
    "print(df[df['class_in_provided_brick'] == True].head())\n",
    "print(len(df[df['class_in_provided_brick'] == False]), 'not recognised by provided Brick schema:')\n",
    "print(df[df['class_in_provided_brick'] == False].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_in_latest_brick'] = df['brick_class'].apply(class_in_brick, args=(g_brick_latest,))\n",
    "print(len(df[df['class_in_latest_brick'] == True]), 'recognised by provided Brick schema:')\n",
    "print(df[df['class_in_latest_brick'] == True].head())\n",
    "print(len(df[df['class_in_latest_brick'] == False]), 'not recognised by provided Brick schema:')\n",
    "print(df[df['class_in_latest_brick'] == False].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brick_definition(cls, g, g_alt=None):\n",
    "    if cls is None:\n",
    "        return None\n",
    "    \n",
    "    # predicate = rdflib.term.URIRef('http://www.w3.org/2004/02/skos/core#definition')\n",
    "    predicate = SKOS['definition']\n",
    "    definition = g.value(subject=cls, predicate=predicate)\n",
    "    \n",
    "    original_cls = cls\n",
    "    while definition is None:\n",
    "        cls = g.value(subject=cls, predicate=RDFS['subClassOf'])\n",
    "        # print(cls)\n",
    "        if cls is None:\n",
    "            break\n",
    "        definition = g.value(subject=cls, predicate=predicate)\n",
    "    \n",
    "    if definition is None and g_alt is not None:\n",
    "        return get_brick_definition(original_cls, g_alt)\n",
    "    \n",
    "    return g.value(subject=cls, predicate=predicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brick_definition'] = df['brick_class'].apply(get_brick_definition, args=(g_brick,))\n",
    "# df['brick_definition'] = df['class'].apply(get_brick_definition, args=(g_brick_latest,))\n",
    "# df['brick_definition'] = df['class'].apply(get_brick_definition, args=(g_brick, g_brick_latest))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'named_unit' not in df.columns:\n",
    "    df['named_unit'] = None\n",
    "if 'anonymous_unit' not in df.columns:\n",
    "    df['anonymous_unit'] = None\n",
    "\n",
    "\n",
    "df = df.assign(unit=lambda x: x['named_unit'].combine_first(x['anonymous_unit']))\n",
    "\n",
    "# def unit_in_brick(unit, g):\n",
    "#     return (unit, None, None) in g\n",
    "\n",
    "\n",
    "# df['unit_in_provided_brick'] = df['named_unit'].apply(class_in_brick, args=(g_brick,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_is_named(r):\n",
    "    if pd.isna(r.unit):\n",
    "        return None\n",
    "    \n",
    "    return not pd.isna(r.named_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unit_is_named'] = df.apply(unit_is_named, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.assign(unit_is_named=lambda x: x['unit'].apply(lambda u: u is not None and u.startswith('unit:')))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mapping file\n",
    "mapping_df = pd.read_csv(mapping_path, index_col=0)\n",
    "\n",
    "# Building B only\n",
    "# mapping_df = mapping_df[mapping_df['Building'] == 'B']\n",
    "\n",
    "# Ignore streams not saved to file\n",
    "mapping_df = mapping_df[mapping_df['Filename'].str.contains('FILE NOT SAVED') == False]\n",
    "\n",
    "mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stream_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_exists_in_mapping(s, mapping_df):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    return str(s).strip() in mapping_df['StreamID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stream_exists_in_mapping'] = df['stream_id'].apply(stream_exists_in_mapping, args=(mapping_df,))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brick_class_in_mapping(s, mapping_df):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    mapping_df['StreamID']\n",
    "    return str(s).strip() in mapping_df['StreamID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df['stream_id'] to string for the join\n",
    "df['stream_id_str'] = df['stream_id'].apply(lambda x: str(x))\n",
    "\n",
    "# Perform the left join\n",
    "df = pd.merge(df, mapping_df[['StreamID', 'strBrickLabel']], how='left', left_on='stream_id_str', right_on='StreamID')\n",
    "\n",
    "# Optionally drop the temporary column 'stream_id_str' and 'StreamID' after the merge\n",
    "df = df.drop(columns=['stream_id_str', 'StreamID'])\n",
    "df.rename(columns={'strBrickLabel': 'brick_class_in_mapping'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brick_class_fragment'] = df['brick_class'].apply(lambda x: str(x.fragment) if x is not None else None)\n",
    "\n",
    "df['brick_class_is_consistent'] = np.where(\n",
    "    pd.isna(df['brick_class_in_mapping']),  # Check if brick_class_in_mapping is empty\n",
    "    None,  # Leave empty where there's no mapping value\n",
    "    df['brick_class_fragment'] == df['brick_class_in_mapping']  # Compare fragment with the mapping\n",
    ")\n",
    "\n",
    "df.drop(columns=['brick_class_fragment'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defrag_uri(s):\n",
    "    if isinstance(s, rdflib.term.URIRef):\n",
    "        if '#' in s:\n",
    "            return s.fragment\n",
    "        elif '/' in s:\n",
    "            return s.split('/')[-1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(defrag_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model_quality.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brick Entities in Building Model Recognised by Brick Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_in_provided_brick = df[['brick_class', 'entity', 'class_in_provided_brick']].copy()\n",
    "entity_in_provided_brick.sort_values(by=['class_in_provided_brick', 'brick_class', 'entity'], inplace=True)\n",
    "entity_in_provided_brick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "to_plot = entity_in_provided_brick[['brick_class', 'class_in_provided_brick']].groupby('class_in_provided_brick').count()\n",
    "to_plot.reset_index(inplace=True)\n",
    "to_plot['class_in_provided_brick'] = to_plot['class_in_provided_brick'].apply(lambda x: 'Recognised' if x else 'Unrecognised')\n",
    "to_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.pie(to_plot, values='brick_class', names='class_in_provided_brick',\n",
    "             title='Proportion of Brick Entities Recognised by Provided Brick Schema',\n",
    "            #  hover_data={'brick_class': True, 'class_in_provided_brick': False}, \n",
    "            #  hover_data={'brick_class': True, 'class_in_provided_brick': False}, \n",
    "            #  labels={'brick_class':'Number of Entities'})\n",
    "             labels={'class_in_provided_brick': 'Class', 'brick_class':'Number of Entities'})\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = entity_in_provided_brick[['brick_class', 'class_in_provided_brick']].copy()\n",
    "# to_plot.reset_index(inplace=True)\n",
    "to_plot['class_in_provided_brick'] = to_plot['class_in_provided_brick'].apply(lambda x: 'Recognised' if x else 'Unrecognised')\n",
    "to_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    # shared_xaxes=True,\n",
    "    vertical_spacing=0.03,\n",
    "    specs=[[{\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\"}]]\n",
    ")\n",
    "\n",
    "labels = to_plot['class_in_provided_brick'].value_counts().index\n",
    "values = to_plot['class_in_provided_brick'].value_counts().values\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(#to_plot, \n",
    "        #    values='brick_class', \n",
    "            labels=labels,\n",
    "              values=values,\n",
    "              textposition='inside', \n",
    "              textinfo='percent+label',\n",
    "              name=\"\",\n",
    "        #    names='class_in_provided_brick',\n",
    "        #    title='Proportion of Brick Entities Recognised by Provided Brick Schema',\n",
    "        #    labels={'class_in_provided_brick': 'Class', 'brick_class':'Number of Entities'}\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Entity ID\", \"Class Recognised\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    title_text=\"Brick Entities in Building Model Recognised by Brick Schema\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    # shared_xaxes=True,\n",
    "    # vertical_spacing=0.1,\n",
    "    vertical_spacing=0.03,\n",
    "    subplot_titles = ['Proportion of Entities', 'Recognised Entities', 'Unrecognised Entities'],\n",
    "    specs=[[{\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\"}],\n",
    "           [{\"type\": \"table\"}]]\n",
    ")\n",
    "\n",
    "labels = to_plot['class_in_provided_brick'].value_counts().index\n",
    "values = to_plot['class_in_provided_brick'].value_counts().values\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(#to_plot, \n",
    "        #    values='brick_class', \n",
    "            labels=labels,\n",
    "              values=values,\n",
    "              textposition='inside', \n",
    "              textinfo='percent+label',\n",
    "              name=\"\",\n",
    "        #    names='class_in_provided_brick',\n",
    "        #    title='Proportion of Brick Entities Recognised by Provided Brick Schema',\n",
    "        #    labels={'class_in_provided_brick': 'Class', 'brick_class':'Number of Entities'}\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "entity_in_provided_brick_true = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == True]\n",
    "entity_in_provided_brick_false = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == False]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Entity ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[entity_in_provided_brick_true[k].tolist() for k in entity_in_provided_brick_true.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Entity ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[entity_in_provided_brick_false[k].tolist() for k in entity_in_provided_brick_false.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=3, col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"Brick Entities in Building Model Recognised by Brick Schema\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    # shared_xaxes=True,\n",
    "    # vertical_spacing=0.1,\n",
    "    # vertical_spacing=0.03,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles = ['Proportion of Entities', 'Unrecognised by Class', 'Unrecognised Entities', 'Recognised Entities'],\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None]]\n",
    ")\n",
    "\n",
    "labels = to_plot['class_in_provided_brick'].value_counts().index\n",
    "values = to_plot['class_in_provided_brick'].value_counts().values\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(#to_plot, \n",
    "        #    values='brick_class', \n",
    "            labels=labels,\n",
    "              values=values,\n",
    "              textposition='inside', \n",
    "              textinfo='percent+label',\n",
    "              name=\"\",\n",
    "        #    names='class_in_provided_brick',\n",
    "        #    title='Proportion of Brick Entities Recognised by Provided Brick Schema',\n",
    "        #    labels={'class_in_provided_brick': 'Class', 'brick_class':'Number of Entities'}\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "entity_in_provided_brick_true = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == True]\n",
    "entity_in_provided_brick_false = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == False]\n",
    "\n",
    "labels = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == False]['brick_class'].value_counts().index\n",
    "values = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == False]['brick_class'].value_counts().values\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(#to_plot, \n",
    "        #    values='brick_class', \n",
    "            labels=labels,\n",
    "              values=values,\n",
    "              textposition='inside', \n",
    "              textinfo='percent+label',\n",
    "            #   textinfo='value+label',\n",
    "              name=\"\",\n",
    "        #    names='class_in_provided_brick',\n",
    "        #    title='Proportion of Brick Entities Recognised by Provided Brick Schema',\n",
    "        #    labels={'class_in_provided_brick': 'Class', 'brick_class':'Number of Entities'}\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Entity ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[entity_in_provided_brick_false[k].tolist() for k in entity_in_provided_brick_false.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Entity ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[entity_in_provided_brick_true[k].tolist() for k in entity_in_provided_brick_true.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"Brick Entities in Building Model Recognised by Brick Schema\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"brick_entities_recognised_by_schema.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources in Building Model with Associated Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_with_units = df[['brick_class', 'stream_id', 'unit', 'unit_is_named']].copy()\n",
    "stream_with_units.dropna(subset=['stream_id'], inplace=True)\n",
    "stream_with_units.sort_values(by=['brick_class', 'stream_id'], inplace=True)\n",
    "# entity_in_provided_brick.sort_values(by=['class_in_provided_brick', 'brick_class', 'entity'], inplace=True)\n",
    "stream_with_units['has_unit'] = stream_with_units['unit'].apply(lambda x: 'No units' if pd.isna(x) else 'Units')\n",
    "stream_with_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_without_units = stream_with_units[pd.isna(stream_with_units['unit'])].copy()\n",
    "streams_without_units.sort_values(by=['brick_class', 'stream_id'], inplace=True)\n",
    "streams_without_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_with_units_labels = stream_with_units['has_unit'].value_counts().index\n",
    "number_with_units_values = stream_with_units['has_unit'].value_counts().values\n",
    "print(number_with_units_labels)\n",
    "print(number_with_units_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_with_named_units = stream_with_units.dropna(subset=['unit']).copy()\n",
    "stream_with_named_units['has_named_unit'] = stream_with_units['unit_is_named'].apply(lambda x: 'Machine readable' if x else 'Not machine readable')\n",
    "stream_with_named_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_with_anonymous_units = stream_with_units[stream_with_units['unit_is_named'] == False]\n",
    "streams_with_anonymous_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_with_named_units_labels = stream_with_named_units['has_named_unit'].value_counts().index\n",
    "number_with_named_units_values = stream_with_named_units['has_named_unit'].value_counts().values\n",
    "print(number_with_named_units_labels)\n",
    "print(number_with_named_units_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles = ['Proportion of Streams with Units', 'Units that are Machine Readable', 'Streams without Units', 'Streams with Non-Machine Readable Units'],\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None]]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=number_with_units_labels,\n",
    "        values=number_with_units_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "entity_in_provided_brick_true = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == True]\n",
    "entity_in_provided_brick_false = entity_in_provided_brick[entity_in_provided_brick['class_in_provided_brick'] == False]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie( \n",
    "        labels=number_with_named_units_labels,\n",
    "        values=number_with_named_units_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Stream ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[streams_without_units[k].tolist() for k in streams_without_units.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Stream ID\", \"Units\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            # values=[entity_in_provided_brick[k].tolist() for k in entity_in_provided_brick.columns[1:]],\n",
    "            values=[streams_with_anonymous_units[k].tolist() for k in streams_with_anonymous_units.columns[:3]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"Data Sources in Building Model with Associated Units\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"data_sources_with_associated_units.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources in Building Model without Timeseries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_data = df[['brick_class', 'stream_id', 'stream_exists_in_mapping']].copy()\n",
    "have_data.dropna(subset=['stream_id'], inplace=True)\n",
    "have_data.sort_values(by=['brick_class', 'stream_id'], inplace=True)\n",
    "have_data['has_data'] = have_data['stream_exists_in_mapping'].apply(lambda x: 'Data' if x else 'No data')\n",
    "have_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_with_data_labels = have_data['has_data'].value_counts().index\n",
    "number_with_data_values = have_data['has_data'].value_counts().values\n",
    "print(number_with_data_labels)\n",
    "print(number_with_data_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_by_class = have_data[have_data['stream_exists_in_mapping'] == False].copy()\n",
    "missing_data_by_class = missing_data_by_class.groupby('brick_class').count()\n",
    "missing_data_by_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_by_class_labels = have_data[have_data['stream_exists_in_mapping'] == False]['brick_class'].value_counts().index\n",
    "missing_data_by_class_values = have_data[have_data['stream_exists_in_mapping'] == False]['brick_class'].value_counts().values\n",
    "print(missing_data_by_class_labels)\n",
    "print(missing_data_by_class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_true = have_data[have_data['stream_exists_in_mapping'] == True]\n",
    "missing_data_false = have_data[have_data['stream_exists_in_mapping'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles = ['Proportion of Data Sources', 'Missing by Class', 'Data Sources with Missing Timeseries Data', 'Data Sources with Available Timeseries Data'],\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None]]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=number_with_data_labels,\n",
    "        values=number_with_data_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=missing_data_by_class_labels,\n",
    "        values=missing_data_by_class_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Stream ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[missing_data_false[k].tolist() for k in missing_data_false.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class\", \"Stream ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[missing_data_true[k].tolist() for k in missing_data_true.columns[:2]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    showlegend=False,\n",
    "    title_text=\"Data Sources in Building Model without Timeseries Data\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"data_sources_without_data.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources with Inconsistent Brick Class between Model and Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_consistency = df[['brick_class', 'brick_class_in_mapping', 'entity', 'brick_class_is_consistent']].copy()\n",
    "class_consistency.dropna(subset=['brick_class_in_mapping'], inplace=True)\n",
    "class_consistency.sort_values(by=['brick_class', 'brick_class_in_mapping', 'entity'], inplace=True)\n",
    "class_consistency['consistency'] = class_consistency['brick_class_is_consistent'].apply(lambda x: 'Consistent' if x else 'Inconsistent')\n",
    "class_consistency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_consistency_labels = class_consistency['consistency'].value_counts().index\n",
    "number_consistency_values = class_consistency['consistency'].value_counts().values\n",
    "print(number_consistency_labels)\n",
    "print(number_consistency_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_classes = class_consistency[class_consistency['brick_class_is_consistent'] == False].copy()\n",
    "inconsistent_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_by_class_labels = inconsistent_classes['brick_class'].value_counts().index\n",
    "consistency_by_class_values = inconsistent_classes['brick_class'].value_counts().values\n",
    "print(consistency_by_class_labels)\n",
    "print(consistency_by_class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    # shared_xaxes=True,\n",
    "    # vertical_spacing=0.1,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles = ['Proportion of Data Sources', 'Inconsistent by Class', 'Data Sources with Inconsistent Brick Class'],\n",
    "    specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"table\", 'colspan': 2}, None]]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=number_consistency_labels,\n",
    "        values=number_consistency_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=consistency_by_class_labels,\n",
    "        values=consistency_by_class_values,\n",
    "        textposition='inside', \n",
    "        textinfo='percent+label',\n",
    "        name=\"\",\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"Brick Class in Model\", \"Brick Class in Mapper\", \"Entity ID\"],\n",
    "            font=dict(size=10),\n",
    "            align=\"left\"\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[inconsistent_classes[k].tolist() for k in inconsistent_classes.columns[:3]],\n",
    "            align = \"left\")\n",
    "    ),\n",
    "    row=2, col=1,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    title_text=\"Data Sources with Inconsistent Brick Class between Model and Mapper\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"data_sources_with_inconsistent_class.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams with blank node units\n",
    "q = '''\n",
    "SELECT ?a ?b\n",
    "WHERE {\n",
    "    ?a brick:hasUnit [ brick:value ?b ] .\n",
    "}\n",
    "'''\n",
    "sparql_to_df(g_building, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams with blank node units\n",
    "q = '''\n",
    "SELECT ?a ?b\n",
    "WHERE {\n",
    "    ?a brick:hasUnit ?b .\n",
    "    ?b rdf:type/rdfs:subClassOf* unit: .\n",
    "}\n",
    "'''\n",
    "sparql_to_df(g_building, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams with proper units\n",
    "q = '''\n",
    "SELECT ?a ?b\n",
    "WHERE {\n",
    "    ?a brick:hasUnit ?b .\n",
    "    filter ( strstarts(str(?b),str(unit:)) ) .\n",
    "}\n",
    "'''\n",
    "sparql_to_df(g_building, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ns_prefix, namespace in g_building.namespaces():\n",
    "    print(f'{ns_prefix}: {namespace}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model_quality_defrag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anonymous_units(s, g):\n",
    "    q = '''\n",
    "    SELECT ?units\n",
    "    WHERE {\n",
    "        ?entity brick:hasUnit [ brick:value ?units ] .\n",
    "    }\n",
    "    '''\n",
    "    return sparql_to_df(g, q, initBindings={'entity': s})\n",
    "\n",
    "df['anonymous_units'] = df['entity'].apply(get_anonymous_units, args=(g_building,))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_units(s, g):\n",
    "    # streams with proper units\n",
    "    q = '''\n",
    "    SELECT ?named_units\n",
    "    WHERE {\n",
    "        ?entity brick:hasUnit ?named_units .\n",
    "        # filter ( strstarts(str(?b),str(unit:)) ) .\n",
    "    }\n",
    "    '''\n",
    "    return sparql_to_df(g, q, initBindings={'entity': s})\n",
    "\n",
    "df['named_units'] = df['entity'].apply(get_named_units, args=(g_building,))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['stream_exists_in_mapping'] = np.where(df['stream_id'].isna(), np.nan, df['stream_id'].str.isin(mapping_df['StreamID']))\n",
    "\n",
    "df['stream_exists_in_mapping'] = np.where(\n",
    "    df['stream_id'].apply(lambda x: pd.isna(str(x).strip())), pd.NA,  # Handle empty Literal\n",
    "    df['stream_id'].apply(lambda x: str(x)).isin(mapping_df['StreamID'])  # Convert Literal to string and check\n",
    ")\n",
    "# df['stream_exists_in_mapping'] = df['stream_exists_in_mapping'].astype('boolean')\n",
    "df['stream_exists_in_mapping'] = df['stream_exists_in_mapping'].apply(\n",
    "    lambda x: pd.NA if pd.isna(x) else bool(x)\n",
    ")\n",
    "\n",
    "df.head()\n",
    "# df[('stream_id' == '')]\n",
    "# df[df['stream_id'] != '']\n",
    "df[pd.isna(df['stream_id'])]\n",
    "# for val in df['stream_id']:\n",
    "#     print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
